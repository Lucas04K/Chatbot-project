{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65b5289",
   "metadata": {},
   "source": [
    "## **Lernziele**\n",
    "\n",
    "Durch das Bearbeiten dieser Übungen werden Sie:\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG) und seine Komponenten verstehen.\n",
    "- PDF-Dokumente effektiv laden, vorverarbeiten und verarbeiten.\n",
    "- Textdaten in Embeddings für effiziente Suche umwandeln.\n",
    "- Dokumenten-Retrieval-Systeme mit LangChain und FAISS implementieren und testen.\n",
    "- Retrieval-Systeme mit kostenlosen Sprachmodellen (LLMs) von ChatGroq integrieren.\n",
    "- Ein interaktives chatbasiertes Frage-Antwort-System aufbauen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Übung 1: Setup und Aufwärmen**\n",
    "\n",
    "In dieser Übung richten Sie Ihre Umgebung ein und wählen ein geeignetes Sprachmodell aus.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Umgebungsvariablen laden:** Stellen Sie sicher, dass Ihre Umgebungsvariablen (z.B. API-Schlüssel, Tokens) sicher gespeichert und geladen werden.\n",
    "2. **LLM auswählen:** Wählen Sie ein kostenloses LLM-Modell von ChatGroq aus.\n",
    "3. **Modell instanziieren:** Erstellen Sie eine Instanz Ihres gewählten Modells."
   ]
  },
  {
   "cell_type": "code",
   "id": "c726e326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:01.477337Z",
     "start_time": "2026-02-26T11:00:01.447152Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a023f458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:45.291853Z",
     "start_time": "2026-02-26T11:00:45.205339Z"
    }
   },
   "source": [
    "# warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "855d3984",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 2: Datenaufnahme**\n",
    "\n",
    "In dieser Übung lernen Sie, PDF-Daten in eine Python-Umgebung zu laden.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **PDF-Loader importieren:** Verwenden Sie LangChains `PyPDFLoader`.\n",
    "2. **PDF-Datei laden:** Erstellen Sie eine Funktion zum Lesen der PDF-Datei.\n",
    "3. **PDF-Inhalt anzeigen:** Geben Sie die Seitenanzahl und den Inhalt der ersten Seite aus."
   ]
  },
  {
   "cell_type": "code",
   "id": "083aff05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:48.369812Z",
     "start_time": "2026-02-26T11:00:47.293446Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data\") \n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    str(data_path),\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"{len(docs)} Dokumente geladen\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Dokumente geladen\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6e85a2ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 3: Dokument-Chunking**\n",
    "\n",
    "Diese Übung führt das Aufteilen großer Dokumente in handhabbare Textblöcke ein.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Text-Splitter importieren:** Verwenden Sie `RecursiveCharacterTextSplitter`.\n",
    "2. **Dokument aufteilen:** Schreiben Sie eine Funktion, die geladene Dokumente in Chunks aufteilt.\n",
    "3. **Funktion testen:** Überprüfen Sie das Ergebnis, indem Sie die resultierenden Chunks anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "id": "d497c03a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:50.772119Z",
     "start_time": "2026-02-26T11:00:50.750202Z"
    }
   },
   "source": [
    "# Import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_documents(documents, chunk_size=200, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    # Just to add id for etch chunks to map it later \n",
    "    for i, chunk in enumerate(chunks):\n",
    "         chunk.metadata.update({\n",
    "        \"id\": f\"chunk_{i}\",\n",
    "    })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "react_chunks = chunk_documents(docs)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d4265a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:53.107150Z",
     "start_time": "2026-02-26T11:00:53.083679Z"
    }
   },
   "source": [
    "# Execute your chunking function and display results here\n",
    "len(react_chunks)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "b8a61a64",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **Übung 4: Embedding und Speicherung**\n",
    "\n",
    "In dieser Übung erstellen Sie Embeddings aus Textblöcken und speichern sie effizient.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embedding-Modell wählen:** Verwenden Sie `sentence-transformers/all-mpnet-base-v2` von Hugging Face.\n",
    "2. **Embeddings generieren:** Wandeln Sie Dokument-Chunks in Embeddings um.\n",
    "3. **Embeddings speichern:** Speichern Sie diese Embeddings lokal mit FAISS."
   ]
  },
  {
   "cell_type": "code",
   "id": "7d59e07d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:55.649170Z",
     "start_time": "2026-02-26T11:00:55.605968Z"
    }
   },
   "source": [
    "# Import libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "def embed_and_store(chunks, db_name):\n",
    "    \"\"\"\n",
    "    This function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a VectorStore called FAISS, \n",
    "    which allows for efficient similarity search\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    # create the vector store \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "        \n",
    "    )\n",
    "    # save VectorStore locally\n",
    "    vectorstore.save_local(f\"../vector_databases/vector_db_{db_name}\")\n",
    "    return vectorstore\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "08151ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T11:00:59.356033Z",
     "start_time": "2026-02-26T11:00:58.607167Z"
    }
   },
   "source": [
    "# Generate embeddings and save them locally\n",
    "all_embedding=embed_and_store(chunks=react_chunks, db_name=\"chatbot\")"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:68\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.__init__\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[import]\u001B[39;00m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:15\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackend\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     11\u001B[39m     export_dynamic_quantized_onnx_model,\n\u001B[32m     12\u001B[39m     export_optimized_onnx_model,\n\u001B[32m     13\u001B[39m     export_static_quantized_openvino_model,\n\u001B[32m     14\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcross_encoder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     16\u001B[39m     CrossEncoder,\n\u001B[32m     17\u001B[39m     CrossEncoderModelCardData,\n\u001B[32m     18\u001B[39m     CrossEncoderTrainer,\n\u001B[32m     19\u001B[39m     CrossEncoderTrainingArguments,\n\u001B[32m     20\u001B[39m )\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:5\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_card\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoderModelCardData\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtrainer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoderTrainer\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtraining_args\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoderTrainingArguments\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/trainer.py:23\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mevaluation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceEvaluator, SequentialEvaluator\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtrainer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformerTrainer\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutil\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_datasets_available, is_training_available\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/sentence_transformers/trainer.py:17\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BatchSampler, ConcatDataset, DataLoader, RandomSampler\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m EvalPrediction, PreTrainedTokenizerBase, Trainer, TrainerCallback\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m transformers_version\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2044\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   2043\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2044\u001B[39m     module = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2045\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2238\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   2237\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m2238\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:2236\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   2235\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2236\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   2237\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m     89\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/trainer.py:62\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhyperparameter_search\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ALL_HYPERPARAMETER_SEARCH_BACKENDS, default_hp_search_backend\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_processing_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseImageProcessor\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mintegrations\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdeepspeed\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     64\u001B[39m     deepspeed_init,\n\u001B[32m     65\u001B[39m     deepspeed_load_checkpoint,\n\u001B[32m   (...)\u001B[39m\u001B[32m     68\u001B[39m     propagate_args_to_deepspeed,\n\u001B[32m     69\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:23\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChannelDimension, ImageInput, get_image_size\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprocessing_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ImagesKwargs, Unpack\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m logging\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:32\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mhuggingface_hub\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_repo, is_offline_mode\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mhuggingface_hub\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdataclasses\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m validate_typed_dict\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mhuggingface_hub\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01merrors\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m EntryNotFoundError\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'validate_typed_dict' from 'huggingface_hub.dataclasses' (/Users/lucas/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/huggingface_hub/dataclasses.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Generate embeddings and save them locally\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m all_embedding=\u001B[43membed_and_store\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreact_chunks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdb_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mchatbot\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36membed_and_store\u001B[39m\u001B[34m(chunks, db_name)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[33;03mThis function uses the open-source embedding model HuggingFaceEmbeddings \u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[33;03mto create embeddings and store those in a VectorStore called FAISS, \u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[33;03mwhich allows for efficient similarity search\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# instantiate embedding model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m embedding = \u001B[43mHuggingFaceEmbeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43msentence-transformers/all-mpnet-base-v2\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencode_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mnormalize_embeddings\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m}\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# create the vector store \u001B[39;00m\n\u001B[32m     18\u001B[39m vectorstore = FAISS.from_documents(\n\u001B[32m     19\u001B[39m     documents=chunks,\n\u001B[32m     20\u001B[39m     embedding=embedding,\n\u001B[32m     21\u001B[39m     distance_strategy=DistanceStrategy.COSINE  \u001B[38;5;66;03m# or DistanceStrategy.DOT or DistanceStrategy.L2 \u001B[39;00m\n\u001B[32m     22\u001B[39m \n\u001B[32m     23\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Chatbot-project/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:74\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.__init__\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     70\u001B[39m     msg = (\n\u001B[32m     71\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCould not import sentence_transformers python package. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     72\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPlease install it with `pip install sentence-transformers`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     73\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n\u001B[32m     76\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model_kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mbackend\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtorch\u001B[39m\u001B[33m\"\u001B[39m) == \u001B[33m\"\u001B[39m\u001B[33mipex\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     77\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_optimum_intel_available() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_ipex_available():\n",
      "\u001B[31mImportError\u001B[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "11ce9bba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 5: Retrieval aus FAISS**\n",
    "\n",
    "Hier lernen Sie, wie man Dokumente aus einer Vektordatenbank mithilfe von Embeddings abruft.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embeddings laden:** Laden Sie gespeicherte Embeddings aus der FAISS-Datenbank.\n",
    "2. **Retrieval implementieren:** Erstellen Sie eine Logik zum Abrufen relevanter Chunks basierend auf Abfragen.\n",
    "3. **Retriever testen:** Führen Sie die Suche mit Beispielabfragen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6775f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 36c00454-a6c7-496f-a3e4-ec76fff61c4c)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(langchain_core.vectorstores.base.VectorStoreRetriever,\n",
       " langchain_community.vectorstores.faiss.FAISS)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement retrieval logic from your FAISS database\n",
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function splits out a retriever object from a local VectorStore\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever ,react_vectorstore\n",
    "\n",
    "# Load the retriever and index\n",
    "react_retriever,react_vectorstore = retrieve_from_vector_db(\"../vector_databases/vector_db_ezb\")\n",
    "type(react_retriever),type(react_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ca40046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stf\\AppData\\Local\\Temp\\ipykernel_10236\\2424041750.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  react_retriever.get_relevant_documents(\"Inflation auf mittlere Sicht\",k=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='ce96cb42-d707-4025-bbd1-0d2b4cd738d2', metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2026-02-18T16:13:13+01:00', 'author': 'Europäische Zentralbank', 'moddate': '2026-02-19T08:48:21+01:00', 'title': 'Wirtschaftsbericht, Ausgabe 1 / 2026', 'source': '../documents/2026-01-ezb-wb-data.pdf', 'total_pages': 135, 'page': 3, 'page_label': '4', 'id': 'chunk_24'}, page_content='bestätigte erneut, dass sich die Inflation auf mittlere Sicht bei seinem Zielwert von \\n2 % stabilisieren dürfte. Die Wirtschaft zeigt sich in einem schwierigen globalen'),\n",
       " Document(id='d45b1616-5562-45ac-a163-7999faf4d4ea', metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2026-02-18T16:13:13+01:00', 'author': 'Europäische Zentralbank', 'moddate': '2026-02-19T08:48:21+01:00', 'title': 'Wirtschaftsbericht, Ausgabe 1 / 2026', 'source': '../documents/2026-01-ezb-wb-data.pdf', 'total_pages': 135, 'page': 6, 'page_label': '7', 'id': 'chunk_84'}, page_content='sorgen, dass sich die Inflation auf mittlere Frist beim Zielwert von 2 % stabilisiert. Die \\nFestlegung des angemessenen geldpolitischen Kurses wird von der Datenlage'),\n",
       " Document(id='bd47bd45-9d12-4f85-87be-ea26f25383f9', metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2026-02-18T16:13:13+01:00', 'author': 'Europäische Zentralbank', 'moddate': '2026-02-19T08:48:21+01:00', 'title': 'Wirtschaftsbericht, Ausgabe 1 / 2026', 'source': '../documents/2026-01-ezb-wb-data.pdf', 'total_pages': 135, 'page': 6, 'page_label': '7', 'id': 'chunk_88'}, page_content='Mandats anzupassen, um für eine nachhaltige Stabilisierung der Inflation beim \\nmittelfristigen Zielwert zu sorgen und um die reibungslose Funktionsfähigkeit der')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your retrieval system with queries\n",
    "react_retriever.get_relevant_documents(\"Inflation auf mittlere Sicht\",k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc5069",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 6: Retrieval mit LLM verbinden**\n",
    "\n",
    "Nun verbinden Sie das Dokument-Retrieval mit dem Sprachmodell.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Retrieval-Chain erstellen:** Verknüpfen Sie Ihr Retrieval-System mit Ihrem instanziierten LLM.\n",
    "2. **Chain testen:** Bestätigen Sie die Funktionalität, indem Sie Antworten aus abgerufenen Dokumenten generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b1d6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Write a function to create retrieval and document processing chains\n",
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain\n",
    "\n",
    "\n",
    "react_retrieval_chain = connect_chains(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d200b6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die EZB will die Inflation mittelfristig bei einem Wert von 2 % stabilisieren.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke your chain with a sample question\n",
    "output = react_retrieval_chain.invoke(\n",
    "    {\"input\": \"Bei welchem Wert will die EZB die Inflation mittelfristig sehen?\"}\n",
    ")\n",
    "output['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6325e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die vorläufige Schnellschätzung von Eurostat weist ein Wirtschaftswachstum von 0,3 % im vierten Quartal 2025 aus. Dieses Wachstum ist hauptsächlich auf die Entwicklung im Euroraum zurückzuführen. Die genauen Details über die Ursachen des Wachstums sind nicht im bereitgestellten Text erwähnt. Die Wirtschaftsentwicklung wird durch verschiedene Indikatoren wie den Arbeitsplatzverlust und den Preisdruck auf der Wertschöpfungskette beurteilt. Die genauen Zahlen und Details zu diesen Indikatoren sind jedoch nicht im bereitgestellten Text enthalten.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_retrieval_chain.invoke(\n",
    "    {\"input\": \"Bitte fasse die Konjunkturentwicklung nach der vorläufigen Schnellschätzung von Eurostat in 5 Sätzen zusammen.\"}\n",
    ")['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b052fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 7: Interaktives Chat-System**\n",
    "\n",
    "In der letzten Übung bauen Sie ein interaktives chatbasiertes Abfragesystem.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Chat-Oberfläche erstellen:** Entwickeln Sie eine einfache Funktion für interaktive Abfragen.\n",
    "2. **Chat ausführen:** Ermöglichen Sie es Nutzern, Fragen zu stellen und sofortige Antworten zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0c0506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja, das weltweite Wirtschaftswachstum hat sich insgesamt weiterhin als robust erwiesen. Dies ist zu verdanken an:\n",
      "\n",
      "1. Kräftiges Wirtschaftswachstum im dritten Quartal 2025\n",
      "2. Robuste Nachfrage nach höher rentierenden Staatsanleihen\n",
      "\n",
      "Diese Faktoren haben dazu beigetragen, dass das weltweite Wirtschaftswachstum stabil und kräftig bleibt.\n",
      "...\n",
      "Das Dokument sagt, dass der Einkaufsmanagerindex (EMI) für die Produktion im verarbeitenden Gewerbe und im Dienstleistungssektor im Januar 2026 weitgehend stabil geblieben ist.\n",
      "...\n",
      "Es scheint, dass der bereitgestellte Text nicht explizit fünf Kernaussagen enthält. Der Text scheint eher ein Fragment zu sein, das verschiedene Ideen und Aussagen enthält, aber keine klaren Kernaussagen. Es gibt jedoch einige Schlüsselaussagen, die ich herausgreifen kann:\n",
      "\n",
      "1. Die Fähigkeiten, Kenntnisse und Kompetenzen für Aktivitäten mit Brennstoffen sind nicht ein separates Spektrum an Fähigkeiten.\n",
      "2. Brennstoffe mit höheren Grenzkosten führen tendenziell zu höheren Strompreisen.\n",
      "3. Die Auswirkungen der Klimapolitik wie erwartet gewesen sind (42% der Befragten).\n",
      "4. Die Grenzkosten von Kernenergie sind in der Regel niedriger als bei anderen Brennstoffen.\n",
      "5. Klimafreundliche Innovationen und Investitionen werden von Friktionen behindert.\n",
      "\n",
      "Bitte beachten Sie, dass diese Aussagen nicht explizit als Kernaussagen bezeichnet werden, sondern eher als Schlüsselaussagen, die sich aus dem Text ergeben.\n",
      "...\n",
      "In dem gegebenen Kontext wird über klimafreundliche Innovationen gesagt, dass sie helfen können, Innovationen umzulenken, die relativen Kosten zu senken und andere Innovationen zu fördern.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Define your interactive chat querying function\n",
    "\n",
    "while True:\n",
    "    # 1. Do something (runs at least once)\n",
    "    user_query = input(\"Frag ans RAG-System: \")\n",
    "    \n",
    "    # 2. Check the \"until\" condition\n",
    "    if user_query == 'quit':\n",
    "        break\n",
    "    print(react_retrieval_chain.invoke({\"input\":user_query})['answer'])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "638c56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your interactive chat system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30ce1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Fazit & Reflexion**\n",
    "\n",
    "Nach Abschluss dieser Übungen:\n",
    "\n",
    "- Fassen Sie die gelernten Schlüsselkonzepte zusammen.\n",
    "- Reflektieren Sie über die Wirksamkeit und Einschränkungen des kostenlosen LLM und des von Ihnen aufgebauten RAG-Systems.\n",
    "- Überlegen Sie, wie Sie Ihr System in praktischen Anwendungen verbessern oder erweitern könnten.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
