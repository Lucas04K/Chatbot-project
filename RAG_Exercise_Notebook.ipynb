{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65b5289",
   "metadata": {},
   "source": [
    "## **Lernziele**\n",
    "\n",
    "Durch das Bearbeiten dieser Übungen werden Sie:\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG) und seine Komponenten verstehen.\n",
    "- PDF-Dokumente effektiv laden, vorverarbeiten und verarbeiten.\n",
    "- Textdaten in Embeddings für effiziente Suche umwandeln.\n",
    "- Dokumenten-Retrieval-Systeme mit LangChain und FAISS implementieren und testen.\n",
    "- Retrieval-Systeme mit kostenlosen Sprachmodellen (LLMs) von ChatGroq integrieren.\n",
    "- Ein interaktives chatbasiertes Frage-Antwort-System aufbauen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Übung 1: Setup und Aufwärmen**\n",
    "\n",
    "In dieser Übung richten Sie Ihre Umgebung ein und wählen ein geeignetes Sprachmodell aus.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Umgebungsvariablen laden:** Stellen Sie sicher, dass Ihre Umgebungsvariablen (z.B. API-Schlüssel, Tokens) sicher gespeichert und geladen werden.\n",
    "2. **LLM auswählen:** Wählen Sie ein kostenloses LLM-Modell von ChatGroq aus.\n",
    "3. **Modell instanziieren:** Erstellen Sie eine Instanz Ihres gewählten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c726e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stf\\workspace_neuefische\\Chatbot-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a023f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\", #\"llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d3984",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 2: Datenaufnahme**\n",
    "\n",
    "In dieser Übung lernen Sie, PDF-Daten in eine Python-Umgebung zu laden.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **PDF-Loader importieren:** Verwenden Sie LangChains `PyPDFLoader`.\n",
    "2. **PDF-Datei laden:** Erstellen Sie eine Funktion zum Lesen der PDF-Datei.\n",
    "3. **PDF-Inhalt anzeigen:** Geben Sie die Seitenanzahl und den Inhalt der ersten Seite aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083aff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Dokumente geladen\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data\") \n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    str(data_path),\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"{len(docs)} Dokumente geladen\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad71ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tag 07, 27.10.2023\n",
      "\n",
      "Logistische Regression\n",
      "\n",
      "---\n",
      "\n",
      "## Grundlegender Überblick\n",
      "\n",
      "- **Überwachtes Lernen**: Nutzt gelabelte Daten zur Modellbildung.\n",
      "- **Klassifikation vs. Regression**:\n",
      "  - Klassifikation ordnet Eingaben diskreten Klassen zu (z.B. Spam/kein Spam).\n",
      "  - Regression sagt kontinuierliche Werte voraus (z.B. Temperatur, Preis).\n",
      "- **Klassifikationsarten**:\n",
      "  - Binär: Zwei Klassen (z.B. traurig/glücklich).\n",
      "  - Multiklassig: Mehr als zwei Klassen (z.B. Katze/Hund/Krokodil).\n",
      "  - Multilabel: Ein Input kann mehreren Klassen zugeordnet werden (z.B. Filmgenres).\n",
      "- **Evaluierungsmetriken**:\n",
      "  - Konfusionsmatrix: True/False Positives/Negatives.\n",
      "  - Accuracy: Anteil korrekter Vorhersagen (irreführend bei unausgewogenen Daten).\n",
      "  - Precision: Anteil korrekter positiver Vorhersagen.\n",
      "  - Recall: Anteil erkannter positiver Fälle.\n",
      "  - F1-Score: Harmonisches Mittel aus Precision und Recall.\n",
      "- **Wahrscheinlichkeiten & Threshold**:\n",
      "  - Klassifikationsmodelle liefern oft Wahrscheinlichkeiten (z.B. Sigmoid-Funktion).\n",
      "  - Threshold bestimmt die Klassenzuordnung (Hyperparameter).\n",
      "- **ROC-Kurve & AUC**:\n",
      "  - ROC-Kurve: True Positive Rate vs. False Positive Rate.\n",
      "  - AUC: Fläche unter der ROC-Kurve (0,5 = Zufall, 1 = perfekt).\n",
      "- **Anwendungsabhängige Metriken**:\n",
      "  - Wahl der Metrik hängt vom Problem ab (z.B. Recall bei Krebsdiagnose).\n",
      "\n",
      "---\n",
      "\n",
      "## Erste inhaltliche Notizen\n",
      "Die logistische Regression ist ein Klassifikationsverfahren, das Wahrscheinlichkeiten für die Zugehörigkeit zu einer Klasse berechnet. Im Gegensatz zur linearen Regression, die kontinuierliche Werte vorhersagt, gibt die logistische Regression diskrete Klassenausgaben (z.B. 0 oder 1). Sie wird häufig für binäre Klassifikationsprobleme eingesetzt, kann aber auch auf Multiklass-Probleme erweitert werden.\n",
      "\n",
      "---\n",
      "\n",
      "## Zeitplan\n",
      "\n",
      "|          Zeit | Inhalt |\n",
      "|--------------:|---|\n",
      "| 09:00 - 10:15 | Daily Review |\n",
      "| 10:15 - 11:00 | Logistische Regression Grundlagen |\n",
      "| 11:15 - 12:00 | Sigmoid-Funktion und Verlustfunktionen |\n",
      "| 12:30 - 13:30 | Mittagspause |\n",
      "| 13:30 - 16:00 | Übungen zur logistischen Regression |\n",
      "| 16:00 - 16:30 | Tägliches Stand-up |\n",
      "| 16:30 - 18:00 | Vertiefung und Anwendungsbeispiele |\n",
      "\n",
      "---\n",
      "\n",
      "## Lexikon\n",
      "\n",
      "| Wording | Definition |\n",
      "|---|---|\n",
      "| Klassifikation | Ein Verfahren des überwachten Lernens, bei dem ein Modell Eingabedaten einer oder mehreren diskreten Klassen zuordnet, zum Beispiel „Spam“ oder „kein Spam“. |\n",
      "| Binäre Klassifikation | Sonderform der Klassifikation mit genau zwei möglichen Klassen, häufig kodiert als positiv (1) und negativ (0). |\n",
      "| Multiklassifikation | Klassifikationsproblem mit mehr als zwei sich gegenseitig ausschließenden Klassen. |\n",
      "| Multilabel-Klassifikation | Klassifikationsform, bei der ein einzelner Input mehreren Klassen gleichzeitig zugeordnet werden kann. |\n",
      "| Regression | Ein Verfahren des überwachten Lernens, bei dem kontinuierliche numerische Werte vorhergesagt werden. |\n",
      "| Sigmoid-Funktion | Mathematische Funktion, die Werte auf einen Bereich zwischen 0 und 1 abbildet. |\n",
      "| Logistische Regression | Klassifikationsmodell, das die Sigmoid-Funktion zur Berechnung von Wahrscheinlichkeiten verwendet. |\n",
      "| Verlustfunktion | Mathematische Funktion, die die Abweichung zwischen Vorhersagen und tatsächlichen Werten misst. |\n",
      "| Gradient Descent | Optimierungsverfahren zur Minimierung der Verlustfunktion durch iterative Anpassung der Modellparameter. |\n",
      "| Threshold | Grenzwert, ab dem eine vorhergesagte Wahrscheinlichkeit in eine Klassenentscheidung umgewandelt wird. |\n",
      "| ROC-Kurve | Grafische Darstellung der True Positive Rate gegen die False Positive Rate für verschiedene Thresholds. |\n",
      "| AUC | Fläche unter der ROC-Kurve, misst die Trennschärfe eines Modells. |\n",
      "\n",
      "---\n",
      "\n",
      "## Notizen\n",
      "\n",
      "### Zusammenfassung der heutigen Inhalte\n",
      "Die Vorlesung behandelte die logistische Regression als Methode für binäre Klassifikation, insbesondere im Kontext von Sentiment-Analyse. Es wurden die Herausforderungen der linearen Regression für Klassifikationsprobleme aufgezeigt und die Sigmoid-Funktion als Lösung eingeführt. Zudem wurde die historische Bedeutung der logistischen Regression in der medizinischen Statistik (Herzinfarkt-Risiko) betont.\n",
      "\n",
      "### Detaillierte Notizen\n",
      "\n",
      "#### Klassifikation vs. Regression\n",
      "- **Klassifikation**: Zuordnung von Eingaben zu diskreten Klassen (z.B. Spam/kein Spam, traurig/glücklich).\n",
      "- **Regression**: Vorhersage kontinuierlicher Werte (z.B. Temperatur, Preis).\n",
      "- Beispiel: Sentimentanalyse basierend auf negativen Wörtern und Smileys.\n",
      "\n",
      "#### Lineare Regression für Klassifikation\n",
      "- Problem: Lineare Regression liefert kontinuierliche Werte, nicht binäre Klassen.\n",
      "- Beispiel mit negativen Wörtern:\n",
      "  - Lineare Regression könnte Vorhersagen wie 0,3 oder 1,2 liefern.\n",
      "  - Threshold bei 0,5: Werte >0,5 als \"negativ\" klassifiziert.\n",
      "- Herausforderung: Ausreißer (z.B. 30 negative Wörter) verschieben die Entscheidungsgrenze drastisch.\n",
      "\n",
      "#### Sigmoid-Funktion als Lösung\n",
      "- **Sigmoid-Funktion**: Wandelt beliebige Werte in Wahrscheinlichkeiten zwischen 0 und 1 um.\n",
      "- Eigenschaften:\n",
      "  - Asymptotisch gegen 0 und 1 bei ±∞.\n",
      "  - Stabiler gegenüber Ausreißern als lineare Regression.\n",
      "\n",
      "#### Mathematische Grundlagen\n",
      "- **Logistische Regression**:\n",
      "  $ P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}} $\n",
      "- **Verlustfunktion (binäre Kreuzentropie)**:\n",
      "  $ L = -\\frac{1}{N} \\sum_{i=1}^N [y_i \\log(p_i) + (1-y_i) \\log(1-p_i)] $\n",
      "- **Gradient Descent**: Iterative Anpassung der Parameter $\\beta_0, \\beta_1$ zur Minimierung des Verlusts.\n",
      "\n",
      "#### Beispiel: Sentimentanalyse\n",
      "- Features:\n",
      "  - Anzahl negativer Wörter ($x_1$).\n",
      "  - Anzahl trauriger Smileys ($x_2$).\n",
      "- Entscheidungsgrenze:\n",
      "  $ \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 = 0 $\n",
      "- Beispiel: Bei $x_1 + x_2 \\geq 3$ wird der Text als \"traurig\" klassifiziert.\n",
      "\n",
      "### Fazit\n",
      "Die logistische Regression ist ein mächtiges Werkzeug für Klassifikationsprobleme, insbesondere wenn es um die Vorhersage von Wahrscheinlichkeiten geht. Im Vergleich zur linearen Regression bietet sie den Vorteil, dass sie direkt diskrete Klassenausgaben liefert und stabiler gegenüber Ausreißern ist. Die Sigmoid-Funktion spielt dabei eine zentrale Rolle, indem sie beliebige Werte in Wahrscheinlichkeiten zwischen 0 und 1 umwandelt. Die Verlustfunktion (binäre Kreuzentropie) und der Gradient Descent sind essentiell für das Training des Modells. In der Praxis ist es wichtig, den richtigen Threshold zu wählen und die Modellleistung mit Metriken wie Precision, Recall und F1-Score zu bewerten.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85a2ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 3: Dokument-Chunking**\n",
    "\n",
    "Diese Übung führt das Aufteilen großer Dokumente in handhabbare Textblöcke ein.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Text-Splitter importieren:** Verwenden Sie `RecursiveCharacterTextSplitter`.\n",
    "2. **Dokument aufteilen:** Schreiben Sie eine Funktion, die geladene Dokumente in Chunks aufteilt.\n",
    "3. **Funktion testen:** Überprüfen Sie das Ergebnis, indem Sie die resultierenden Chunks anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645549c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_docs = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e404d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d497c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 03\n",
      "Tag 04\n",
      "Tag 06\n",
      "Tag 07\n",
      "Tag 08\n",
      "Tag 9\n",
      "Tag 11\n",
      "Tag 13\n",
      "Tag 14\n",
      "Tag 16\n",
      "Tag 16\n",
      "Tag 17\n",
      "Tag 18\n",
      "Tag 21\n",
      "Tag 22\n",
      "Tag 23\n",
      "Tag 24\n",
      "Tag 25\n",
      "Tag 27\n",
      "Tag 28\n",
      "Tag 10\n",
      "Tag 12\n",
      "Tag 26\n"
     ]
    }
   ],
   "source": [
    "# Import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_documents(documents, chunk_size=400, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    # Just to add id for etch chunks to map it later \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        days = re.findall(r\"Tag \\d{1,2}\", chunk.page_content)\n",
    "        chunk.metadata.update({\n",
    "            \"id\": f\"chunk_{i}\"\n",
    "            })\n",
    "        if len(days) > 0:\n",
    "            chunk.metadata.update({\n",
    "                \"day\": days[0]\n",
    "            })\n",
    "            print(days[0])\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "react_chunks = chunk_documents(react_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "717ef4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\protocol_26-01-21.md', 'id': 'chunk_0'}, page_content='# Tag 03, 21.01.2026\\n\\nExplorative Datenanalyse (kurz EDA)\\n\\n---\\n## __Grundlegender Überblick__\\n\\n* Grundlegende Begrifflichkeiten in der EDA\\n* Was ist EDA und warum machen wir das?\\n* Arten von EDA\\n* Schätzungen\\n* Datentypen\\n* Univariate EDA - Berechnungen von Mittelwert, Median und Modus\\n* Streuung von Daten\\n\\n---\\n##  __Zeitplan__')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4265a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute your chunking function and display results here\n",
    "len(react_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a61a64",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **Übung 4: Embedding und Speicherung**\n",
    "\n",
    "In dieser Übung erstellen Sie Embeddings aus Textblöcken und speichern sie effizient.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embedding-Modell wählen:** Verwenden Sie `sentence-transformers/all-mpnet-base-v2` von Hugging Face.\n",
    "2. **Embeddings generieren:** Wandeln Sie Dokument-Chunks in Embeddings um.\n",
    "3. **Embeddings speichern:** Speichern Sie diese Embeddings lokal mit FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d59e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "def embed_and_store(chunks, db_name):\n",
    "    \"\"\"\n",
    "    This function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a VectorStore called FAISS, \n",
    "    which allows for efficient similarity search\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    # create the vector store \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "        \n",
    "    )\n",
    "    # save VectorStore locally\n",
    "    vectorstore.save_local(f\"../vector_databases/vector_db_{db_name}\")\n",
    "    return vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08151ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings and save them locally\n",
    "all_embedding=embed_and_store(chunks=react_chunks, db_name=\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce9bba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 5: Retrieval aus FAISS**\n",
    "\n",
    "Hier lernen Sie, wie man Dokumente aus einer Vektordatenbank mithilfe von Embeddings abruft.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embeddings laden:** Laden Sie gespeicherte Embeddings aus der FAISS-Datenbank.\n",
    "2. **Retrieval implementieren:** Erstellen Sie eine Logik zum Abrufen relevanter Chunks basierend auf Abfragen.\n",
    "3. **Retriever testen:** Führen Sie die Suche mit Beispielabfragen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6775f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain_core.vectorstores.base.VectorStoreRetriever,\n",
       " langchain_community.vectorstores.faiss.FAISS)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement retrieval logic from your FAISS database\n",
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function splits out a retriever object from a local VectorStore\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever ,react_vectorstore\n",
    "\n",
    "# Load the retriever and index\n",
    "react_retriever,react_vectorstore = retrieve_from_vector_db(\"../vector_databases/vector_db_chatbot\")\n",
    "type(react_retriever),type(react_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ca40046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='cfecc979-f5c4-4ea5-91da-7145de1fe01c', metadata={'source': 'data\\\\protocol_26-02-18_clustering.md', 'id': 'chunk_429'}, page_content='---\\n\\n## Anekdote\\n\\nAutor Borges  \\nEnzyklopädie \"Emporio celestial de conocimientos benévolos\"  \\nKlassifizierung von  Tieren, wenn auch nach eher absurden Kriterien\\n\\n---\\n\\n## Haupt Take-Away'),\n",
       " Document(id='91f2064e-50de-4c10-bfab-30dc96c284aa', metadata={'source': 'data\\\\protocol_26_02_23.md', 'id': 'chunk_622'}, page_content='---\\n##  __Zeitplan__\\n\\n|Zeit|Inhalt|\\n|---|---|\\n|09:00 - 09:25|Daily Review|\\n|10:00 - 11:15|Erste theoretische Inputs|\\n|11:15 - 12:15|Mittagspause| \\n|13:30 - 16:00|Praktische Übungen|\\n|16:00 - 16:30|Tägliches Stand-up|\\n|16:30 - 18:00|Übungen und Abschluss|\\n\\n\\n---\\n## __Erste inhaltliche Notizen__\\n\\n\\n### Anekdote\\nDie Fluglinie Air Canada, deren ChatBot behauptete 90 Tage dauerte  eine Rücküberweisung'),\n",
       " Document(id='67d8d7cb-deb2-4f6e-9d4d-57ea83544912', metadata={'source': 'data\\\\protocol_26-02-11.md', 'id': 'chunk_348'}, page_content='---\\n\\n## 9. Anwendungsbereiche')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your retrieval system with queries\n",
    "react_retriever.get_relevant_documents(\"Anekdote\",k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc5069",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 6: Retrieval mit LLM verbinden**\n",
    "\n",
    "Nun verbinden Sie das Dokument-Retrieval mit dem Sprachmodell.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Retrieval-Chain erstellen:** Verknüpfen Sie Ihr Retrieval-System mit Ihrem instanziierten LLM.\n",
    "2. **Chain testen:** Bestätigen Sie die Funktionalität, indem Sie Antworten aus abgerufenen Dokumenten generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b1d6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Write a function to create retrieval and document processing chains\n",
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain\n",
    "\n",
    "\n",
    "react_retrieval_chain = connect_chains(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d200b6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Datum des Themas von Tag 21 ist nicht explizit angegeben\n",
      " Es gibt jedoch eine Zeile \"Tag 21, 16\n",
      "02\n",
      "2026\" am Anfang des Kontexts, die wahrscheinlich das Datum des Themas von Tag 21 ist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke your chain with a sample question\n",
    "output = react_retrieval_chain.invoke(\n",
    "    {\"input\": \"In den Metadaten ist day angegeben und mit Werten wie z.B. 'Tag 9' gefüllt. Welches Datum war das Thema von Tag 21?'\"}\n",
    ")\n",
    "answer_list = output['answer'].split(\".\")\n",
    "for sentence in answer_list:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b052fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 7: Interaktives Chat-System**\n",
    "\n",
    "In der letzten Übung bauen Sie ein interaktives chatbasiertes Abfragesystem.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Chat-Oberfläche erstellen:** Entwickeln Sie eine einfache Funktion für interaktive Abfragen.\n",
    "2. **Chat ausführen:** Ermöglichen Sie es Nutzern, Fragen zu stellen und sofortige Antworten zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja, das weltweite Wirtschaftswachstum hat sich insgesamt weiterhin als robust erwiesen. Dies ist zu verdanken an:\n",
      "\n",
      "1. Kräftiges Wirtschaftswachstum im dritten Quartal 2025\n",
      "2. Robuste Nachfrage nach höher rentierenden Staatsanleihen\n",
      "\n",
      "Diese Faktoren haben dazu beigetragen, dass das weltweite Wirtschaftswachstum stabil und kräftig bleibt.\n",
      "...\n",
      "Das Dokument sagt, dass der Einkaufsmanagerindex (EMI) für die Produktion im verarbeitenden Gewerbe und im Dienstleistungssektor im Januar 2026 weitgehend stabil geblieben ist.\n",
      "...\n",
      "Es scheint, dass der bereitgestellte Text nicht explizit fünf Kernaussagen enthält. Der Text scheint eher ein Fragment zu sein, das verschiedene Ideen und Aussagen enthält, aber keine klaren Kernaussagen. Es gibt jedoch einige Schlüsselaussagen, die ich herausgreifen kann:\n",
      "\n",
      "1. Die Fähigkeiten, Kenntnisse und Kompetenzen für Aktivitäten mit Brennstoffen sind nicht ein separates Spektrum an Fähigkeiten.\n",
      "2. Brennstoffe mit höheren Grenzkosten führen tendenziell zu höheren Strompreisen.\n",
      "3. Die Auswirkungen der Klimapolitik wie erwartet gewesen sind (42% der Befragten).\n",
      "4. Die Grenzkosten von Kernenergie sind in der Regel niedriger als bei anderen Brennstoffen.\n",
      "5. Klimafreundliche Innovationen und Investitionen werden von Friktionen behindert.\n",
      "\n",
      "Bitte beachten Sie, dass diese Aussagen nicht explizit als Kernaussagen bezeichnet werden, sondern eher als Schlüsselaussagen, die sich aus dem Text ergeben.\n",
      "...\n",
      "In dem gegebenen Kontext wird über klimafreundliche Innovationen gesagt, dass sie helfen können, Innovationen umzulenken, die relativen Kosten zu senken und andere Innovationen zu fördern.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Define your interactive chat querying function\n",
    "\n",
    "while True:\n",
    "    # 1. Do something (runs at least once)\n",
    "    user_query = input(\"Frage ans RAG-System: \")\n",
    "    \n",
    "    # 2. Check the \"until\" condition\n",
    "    if user_query == 'quit':\n",
    "        break\n",
    "    print(react_retrieval_chain.invoke({\"input\":user_query})['answer'])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "638c56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your interactive chat system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30ce1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Fazit & Reflexion**\n",
    "\n",
    "Nach Abschluss dieser Übungen:\n",
    "\n",
    "- Fassen Sie die gelernten Schlüsselkonzepte zusammen.\n",
    "- Reflektieren Sie über die Wirksamkeit und Einschränkungen des kostenlosen LLM und des von Ihnen aufgebauten RAG-Systems.\n",
    "- Überlegen Sie, wie Sie Ihr System in praktischen Anwendungen verbessern oder erweitern könnten.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
