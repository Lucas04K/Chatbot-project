{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e65b5289",
   "metadata": {},
   "source": [
    "## **Lernziele**\n",
    "\n",
    "Durch das Bearbeiten dieser Übungen werden Sie:\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG) und seine Komponenten verstehen.\n",
    "- PDF-Dokumente effektiv laden, vorverarbeiten und verarbeiten.\n",
    "- Textdaten in Embeddings für effiziente Suche umwandeln.\n",
    "- Dokumenten-Retrieval-Systeme mit LangChain und FAISS implementieren und testen.\n",
    "- Retrieval-Systeme mit kostenlosen Sprachmodellen (LLMs) von ChatGroq integrieren.\n",
    "- Ein interaktives chatbasiertes Frage-Antwort-System aufbauen.\n",
    "\n",
    "---\n",
    "\n",
    "## **Übung 1: Setup und Aufwärmen**\n",
    "\n",
    "In dieser Übung richten Sie Ihre Umgebung ein und wählen ein geeignetes Sprachmodell aus.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Umgebungsvariablen laden:** Stellen Sie sicher, dass Ihre Umgebungsvariablen (z.B. API-Schlüssel, Tokens) sicher gespeichert und geladen werden.\n",
    "2. **LLM auswählen:** Wählen Sie ein kostenloses LLM-Modell von ChatGroq aus.\n",
    "3. **Modell instanziieren:** Erstellen Sie eine Instanz Ihres gewählten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c726e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stf\\workspace_neuefische\\Chatbot-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a023f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\", #\"llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d3984",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 2: Datenaufnahme**\n",
    "\n",
    "In dieser Übung lernen Sie, PDF-Daten in eine Python-Umgebung zu laden.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **PDF-Loader importieren:** Verwenden Sie LangChains `PyPDFLoader`.\n",
    "2. **PDF-Datei laden:** Erstellen Sie eine Funktion zum Lesen der PDF-Datei.\n",
    "3. **PDF-Inhalt anzeigen:** Geben Sie die Seitenanzahl und den Inhalt der ersten Seite aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083aff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Dokumente geladen\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data\") \n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    str(data_path),\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"{len(docs)} Dokumente geladen\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad71ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Day 8, 17.12.2025\n",
      "Protocol writer: Lisa\n",
      "\n",
      "---\n",
      "## __Introduction__\n",
      "We started the morning with a career course repetition of last week's introduction and collaborated on the protocol for day 7. Then we got introduced to Strings and the many different built-in methods to handle them and did a group exercise on them. We spent the afternoon first discussing the exercise solution, then solving various git/VSCode issues and discussing protocol process (to be continued tomorrow).\n",
      "\n",
      "Main topics of the day: Strings, git process for daily protocol & exercises \n",
      "\n",
      "Next protocol writer for day 9: Gabriela\n",
      "\n",
      "## __Schedule__ \n",
      "|Time|Notes|\n",
      "|---|---|\n",
      "|09:00 - 10:00|Career Course|\n",
      "|10:00 - 10:30|Protocol|\n",
      "|10:30 - 12:00|Strings| \n",
      "|12:00 - 13:00|Lunch Break|  \n",
      "|13:00 - 14:00|Group Exercise & Self-Help| \n",
      "|14:00 - 15:00|Discuss String Exercise| \n",
      "|15:00 - 16:00|Trying to solve git issues|\n",
      "\n",
      "---\n",
      "\n",
      "## __Strings__ \n",
      "* Some important commands\n",
      "    * adding \\n to start a new line in a string (important: no space after the character)\n",
      "    * if you use ''' (3 single quotes) to wrap your text, it means you can add formatted multi-line text, it will recognize the line breaks you have made\n",
      "* using **f strings** to include variables when printing strings\n",
      "* **concatenating** strings\n",
      "* **slicing** strings and using indexes to access separate items [characters] of the sliced up string\n",
      "* accessing string characters by using an index (important: python is a zero-indexed language, meaning index starts at 0)\n",
      "* String methods\n",
      "    * .upper() converts a string to uppercase\n",
      "    * .lower() converts a string to lowercase\n",
      "    * .strip() removes whitspace from beginning and end of a string\n",
      "    * .replace(old, new) replaces all occurences of the old substring with new\n",
      "    * .split(separator) divides a string into a list where each word is a list item\n",
      "    * .capitalize() capitalizes the first word\n",
      "\n",
      "\n",
      "## __User Input__\n",
      "* input() asks the user to enter an input and converts it into a string \n",
      "    * be aware it is _always_ saved as a string, if you need a different data type, you need to transform it - **typecasting** int(input())\n",
      "    * input() triggers a pop-up window that user needs to fill to continue running the code\n",
      "* for user output, use print() like we've learned\n",
      "\n",
      "## __Protocol Process__\n",
      "### __Locally/in VSCode__\n",
      "* Open .md file for existing day or create a new one: Day_[number]_[DD-MM-YY]\n",
      "* Open repo da-daily-protocol..\n",
      "* Check if you are in your own branch and NOT in main (command \"git branch\" lists the branches, the highlighted one is the one you are in)\n",
      "    * If you're in main, change into your own branch with \"git checkout [your_branch_name]\"\n",
      "* Write protocol\n",
      "* Save changes (CTRL+S on Windows or CMD+S)\n",
      "* Next day: meet at 9 (Wednesdays: 11:30!) to collaborate on protocol\n",
      "* Save changes (CTRL+S on Windows or CMD+S)\n",
      "* Use command: \"git add .\" to stage files\n",
      "* Use command: \"git commit -m '[commit_message]\"\n",
      "* Use command: \"git push\" to push changes to your branch\n",
      "* Switch to github.com and create a pull request (green button)\n",
      "    * explain your changes in the PR message\n",
      "    * choose 2 reviewers\n",
      "    * for reviewers: review changes, choose \"comment\", \"approve\" or \"request changes\"\n",
      "* after both reviewers approve PR, merge it (green button on the bottom of the PR on github.com)\n",
      "\n",
      "* When it's your turn again to write the protocol and you want to work locally on the same branch, you need to do the following steps before you can push your new protocol\n",
      "    * switch to the main branch\n",
      "    * git pull from the main branch\n",
      "    * switch to your own branch again\n",
      "    * merge main into your own branch\n",
      "\n",
      "## __Process for daily exercises__\n",
      "Save your exercises and keep input from Merna up-to-date\n",
      "\n",
      "### __Upload your exercises to your own branch (never to main!)__\n",
      "* Work on exercises locally \n",
      "    * Student creates branch (needs to happen only once) (git branch [name_own_branch])\n",
      "    * Student stands on feature branch locally (git checkout [name_own_branch])\n",
      "    * Student works on exercises in VSCode editors space\n",
      "    * Student saves work in feature branch\n",
      "       * save changes locally\n",
      "       * stage files (git add .)\n",
      "       * commit changes to your branch (git commit -m '[commit_message]')\n",
      "* Update exercises to our fork (never to the original repo, only Merna works on that)\n",
      "    * Student updates remote repo (git push -u origin)\n",
      "\n",
      "### __Get Merna's updates to Code Along files into your VSCode__\n",
      "* Merna works on code along\n",
      "* Merna pushes to neuefische repo main\n",
      "    * For the first time: Student forks (creates their own copy of the original repo on github) \n",
      "    * After first time: go to GitHub\n",
      "      * go to your fork (which you can recognize by [your git hub name]/da-da-081225-python-module\n",
      "      * click \"sync fork\" button to sync Merna's changes\n",
      "* Get updates locally\n",
      "   * go back to VSCode\n",
      "      * go to your main (git checkout main)\n",
      "      * pull changes to main (git pull)\n",
      "      * go to your own branch (git checkout [name_own_branch])\n",
      "      * merge files from main into your solutions branch (git merge main)\n",
      "\n",
      "\n",
      "      \n",
      "   \n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85a2ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 3: Dokument-Chunking**\n",
    "\n",
    "Diese Übung führt das Aufteilen großer Dokumente in handhabbare Textblöcke ein.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Text-Splitter importieren:** Verwenden Sie `RecursiveCharacterTextSplitter`.\n",
    "2. **Dokument aufteilen:** Schreiben Sie eine Funktion, die geladene Dokumente in Chunks aufteilt.\n",
    "3. **Funktion testen:** Überprüfen Sie das Ergebnis, indem Sie die resultierenden Chunks anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645549c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_docs = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d497c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_documents(documents, chunk_size=200, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    # Just to add id for etch chunks to map it later \n",
    "    for i, chunk in enumerate(chunks):\n",
    "         chunk.metadata.update({\n",
    "        \"id\": f\"chunk_{i}\",\n",
    "    })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "react_chunks = chunk_documents(react_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4265a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute your chunking function and display results here\n",
    "len(react_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a61a64",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **Übung 4: Embedding und Speicherung**\n",
    "\n",
    "In dieser Übung erstellen Sie Embeddings aus Textblöcken und speichern sie effizient.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embedding-Modell wählen:** Verwenden Sie `sentence-transformers/all-mpnet-base-v2` von Hugging Face.\n",
    "2. **Embeddings generieren:** Wandeln Sie Dokument-Chunks in Embeddings um.\n",
    "3. **Embeddings speichern:** Speichern Sie diese Embeddings lokal mit FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d59e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "def embed_and_store(chunks, db_name):\n",
    "    \"\"\"\n",
    "    This function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a VectorStore called FAISS, \n",
    "    which allows for efficient similarity search\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    # create the vector store \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "        \n",
    "    )\n",
    "    # save VectorStore locally\n",
    "    vectorstore.save_local(f\"../vector_databases/vector_db_{db_name}\")\n",
    "    return vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08151ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 3eb4ed36-ab5b-42b8-8ad3-607261523351)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings and save them locally\n",
    "all_embedding=embed_and_store(chunks=react_chunks, db_name=\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce9bba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 5: Retrieval aus FAISS**\n",
    "\n",
    "Hier lernen Sie, wie man Dokumente aus einer Vektordatenbank mithilfe von Embeddings abruft.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Embeddings laden:** Laden Sie gespeicherte Embeddings aus der FAISS-Datenbank.\n",
    "2. **Retrieval implementieren:** Erstellen Sie eine Logik zum Abrufen relevanter Chunks basierend auf Abfragen.\n",
    "3. **Retriever testen:** Führen Sie die Suche mit Beispielabfragen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6775f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain_core.vectorstores.base.VectorStoreRetriever,\n",
       " langchain_community.vectorstores.faiss.FAISS)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement retrieval logic from your FAISS database\n",
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function splits out a retriever object from a local VectorStore\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "        distance_strategy=DistanceStrategy.COSINE  # or DistanceStrategy.DOT or DistanceStrategy.L2 \n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever ,react_vectorstore\n",
    "\n",
    "# Load the retriever and index\n",
    "react_retriever,react_vectorstore = retrieve_from_vector_db(\"../vector_databases/vector_db_ezb\")\n",
    "type(react_retriever),type(react_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca40046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stf\\AppData\\Local\\Temp\\ipykernel_6504\\184179367.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  react_retriever.get_relevant_documents(\"Anekdote\",k=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='42c48773-00c5-471e-a576-bf25132e945d', metadata={'source': 'data\\\\Day_26_02_02_26.md', 'id': 'chunk_738'}, page_content='Day 26, 02.02.2026  \\nProtocol writer: Preeti\\n\\n---\\n\\n## __Introduction__  \\nThe session was on A/B Testing\\n\\n---'),\n",
       " Document(id='4bed9e32-21e4-4f4d-a5bc-ffc639395b0c', metadata={'source': 'data\\\\Day_08_17-12-25.md', 'id': 'chunk_82'}, page_content='---'),\n",
       " Document(id='39e48a48-9f9c-45e6-9836-1ebde6f8f1c1', metadata={'source': 'data\\\\Day_09_18-12-25.md', 'id': 'chunk_128'}, page_content='---')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your retrieval system with queries\n",
    "react_retriever.get_relevant_documents(\"Anekdote\",k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc5069",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 6: Retrieval mit LLM verbinden**\n",
    "\n",
    "Nun verbinden Sie das Dokument-Retrieval mit dem Sprachmodell.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Retrieval-Chain erstellen:** Verknüpfen Sie Ihr Retrieval-System mit Ihrem instanziierten LLM.\n",
    "2. **Chain testen:** Bestätigen Sie die Funktionalität, indem Sie Antworten aus abgerufenen Dokumenten generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b1d6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Write a function to create retrieval and document processing chains\n",
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain\n",
    "\n",
    "\n",
    "react_retrieval_chain = connect_chains(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d200b6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich kann dir auf Grundlage des Kontextes folgendes sagen:\\n\\nDer Tag 13 war am 08.01.2026. Der Protokollschreiber war Preeti.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke your chain with a sample question\n",
    "output = react_retrieval_chain.invoke(\n",
    "    {\"input\": \"gib einen grundlegenden Überblick über den Tag 13'?\"}\n",
    ")\n",
    "output['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6325e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die vorläufige Schnellschätzung von Eurostat weist ein Wirtschaftswachstum von 0,3 % im vierten Quartal 2025 aus. Dieses Wachstum ist hauptsächlich auf die Entwicklung im Euroraum zurückzuführen. Die genauen Details über die Ursachen des Wachstums sind nicht im bereitgestellten Text erwähnt. Die Wirtschaftsentwicklung wird durch verschiedene Indikatoren wie den Arbeitsplatzverlust und den Preisdruck auf der Wertschöpfungskette beurteilt. Die genauen Zahlen und Details zu diesen Indikatoren sind jedoch nicht im bereitgestellten Text enthalten.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_retrieval_chain.invoke(\n",
    "    {\"input\": \"Bitte fasse die Konjunkturentwicklung nach der vorläufigen Schnellschätzung von Eurostat in 5 Sätzen zusammen.\"}\n",
    ")['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b052fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Übung 7: Interaktives Chat-System**\n",
    "\n",
    "In der letzten Übung bauen Sie ein interaktives chatbasiertes Abfragesystem.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Chat-Oberfläche erstellen:** Entwickeln Sie eine einfache Funktion für interaktive Abfragen.\n",
    "2. **Chat ausführen:** Ermöglichen Sie es Nutzern, Fragen zu stellen und sofortige Antworten zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0c0506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja, das weltweite Wirtschaftswachstum hat sich insgesamt weiterhin als robust erwiesen. Dies ist zu verdanken an:\n",
      "\n",
      "1. Kräftiges Wirtschaftswachstum im dritten Quartal 2025\n",
      "2. Robuste Nachfrage nach höher rentierenden Staatsanleihen\n",
      "\n",
      "Diese Faktoren haben dazu beigetragen, dass das weltweite Wirtschaftswachstum stabil und kräftig bleibt.\n",
      "...\n",
      "Das Dokument sagt, dass der Einkaufsmanagerindex (EMI) für die Produktion im verarbeitenden Gewerbe und im Dienstleistungssektor im Januar 2026 weitgehend stabil geblieben ist.\n",
      "...\n",
      "Es scheint, dass der bereitgestellte Text nicht explizit fünf Kernaussagen enthält. Der Text scheint eher ein Fragment zu sein, das verschiedene Ideen und Aussagen enthält, aber keine klaren Kernaussagen. Es gibt jedoch einige Schlüsselaussagen, die ich herausgreifen kann:\n",
      "\n",
      "1. Die Fähigkeiten, Kenntnisse und Kompetenzen für Aktivitäten mit Brennstoffen sind nicht ein separates Spektrum an Fähigkeiten.\n",
      "2. Brennstoffe mit höheren Grenzkosten führen tendenziell zu höheren Strompreisen.\n",
      "3. Die Auswirkungen der Klimapolitik wie erwartet gewesen sind (42% der Befragten).\n",
      "4. Die Grenzkosten von Kernenergie sind in der Regel niedriger als bei anderen Brennstoffen.\n",
      "5. Klimafreundliche Innovationen und Investitionen werden von Friktionen behindert.\n",
      "\n",
      "Bitte beachten Sie, dass diese Aussagen nicht explizit als Kernaussagen bezeichnet werden, sondern eher als Schlüsselaussagen, die sich aus dem Text ergeben.\n",
      "...\n",
      "In dem gegebenen Kontext wird über klimafreundliche Innovationen gesagt, dass sie helfen können, Innovationen umzulenken, die relativen Kosten zu senken und andere Innovationen zu fördern.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Define your interactive chat querying function\n",
    "\n",
    "while True:\n",
    "    # 1. Do something (runs at least once)\n",
    "    user_query = input(\"Frag ans RAG-System: \")\n",
    "    \n",
    "    # 2. Check the \"until\" condition\n",
    "    if user_query == 'quit':\n",
    "        break\n",
    "    print(react_retrieval_chain.invoke({\"input\":user_query})['answer'])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "638c56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your interactive chat system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30ce1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Fazit & Reflexion**\n",
    "\n",
    "Nach Abschluss dieser Übungen:\n",
    "\n",
    "- Fassen Sie die gelernten Schlüsselkonzepte zusammen.\n",
    "- Reflektieren Sie über die Wirksamkeit und Einschränkungen des kostenlosen LLM und des von Ihnen aufgebauten RAG-Systems.\n",
    "- Überlegen Sie, wie Sie Ihr System in praktischen Anwendungen verbessern oder erweitern könnten.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
