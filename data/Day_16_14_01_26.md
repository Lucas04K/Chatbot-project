# Day 16, 14.02.2026
Protocol writer: Soheila

---
## __Introduction__
The goal of this lecture was to understand how to inspect, clean, and prepare messy datasets using pandas. We focused especially on missing data, incorrect formats, and improving data quality so that reliable analysis becomes possible. We spent the afternoon doing the exercise, and discussing the solutions tomorrow.

Main topics of the day: Data cleansing & missing data & exercises.

Next protocol writer for day 17: Islam

## __Schedule__ 
|Time|Notes|
|09:00 - 11:30|Self Study and time for career|
|11:30 - 12:00|Daily protocol & recap| 
|12:00 - 13:00|Lunch Break|
|13:00 - 15:30|Data cleansing & missing data lecture| 
|15:30 - 17:00| Data cleansing & missing data exercise|

---

## __Objectives__ 
By the end of this lecture, we learned how to:
- __Inspect a dataframe__

- __Rename columns__

- __Replace values in columns__

- __Drop duplicate rows__

- __Change column data types__

- __Deal with missing values__

- __Create new columns__

### Why Data Cleansing Is Important
Real-world data is often messy and inconsistent. Data cleaning is time-consuming but essential for any data-related job. Messy data arises because:
- Poorly designed forms
- Values saved incorrectly
-  Missing validation during data entry
- Mixed data types (numbers + strings)

Cleaning data helps to:
-  Identify incorrect, incomplete, or irrelevant data 
- Fix data quality issues
- Ensure future analyses are accurate

### Missing Data – Conceptual Overview
Missing or corrupted data can appear in many forms:

- NaN or null values
- Empty strings ("")
- Placeholder values ("unknown", "?", "uncategorized")
- Invalid numeric values (e.g. -1, -99)

-⚠️ Even if a cell is not technically empty, it may be logically missing.

### Causes of Missing Data

- Failure of measurement or data collection
- Poor form design
- Missing validation rules
- Incorrect data storage

Example: Age stored sometimes as number, sometimes as text; Dates saved in multiple formats.

## 1. __Inspecting a DataFrame__

- `df.info()` → Shows column names, types, non-null counts, missing values

- `df.describe()` → Numerical statistics and potential outliers

- `df.describe(include='O')` OR `de.describe(include=[O])`→ Unique values, mode, duplicates

- df.describe(include=[object])

- Detect missing values:
`df.isnull()`
`df.isnull().sum()`

- `df.isna()` is the same as `df.isnull()`


### Observation Documentation: Always note:

- Columns with missing values
- Wrong data types
- Unusual or damaged values
---
## 2. __Renaming Columns__
- Rename all columns
`df.columns = ['cn1', 'cn2', 'cn3', 'cn4']`

- Rename selected columns:
`df.rename(columns={'cn1':'new_cn'}, inplace=True)`

- Optimized method for all columns:
`df.columns = df.columns.str.lower()`
---
## 3. __Cleaning Column Values (Strings)__
- Remove unwanted characters in date column:
`df['date'] = df['date'].str.replace('"', '')`

- check changes:
`df.head()`
---
## 4.__Fixing Individual Corrupted Values__
- Example: One date with missing slashes
- Works for small datasets;
`df.iloc[25, df.columns.get_loc('date')] = '2020/12/26'`

- check changes:
`df.head()`
---
### 5.__Dropping Duplicate Rows__
check how many duplicated we have
- `df.duplicated().sum()`

how many true we have in this dataframe
- `df.drop_duplicates(inplace=True)`

remove the duplicated ones
- `df.reset_index(drop=True, inplace=True)`

with inplace our changes will be applied to the existing dataframe
---
### 6.__changing column-type of Date-column to a specific type that python offers:__

* this method converts the column to date and time format only.

* changing the type of a column and put them into the new columns
`df['date'] = pd.to_datetime(df['date'])`
* rounded the values of column and changed into the integer 
`df['calories'] = df['calories'].round().astype('Int64')`

### 7.__Dealing with Missing Values__
* When filling missing values:
    * Explain that the replacement value must match the column type:
        * If the column is datetime → replacement must be datetime
        * If numeric → replacement must be numeric
    * Otherwise pandas may upcast the column or throw errors.
* Mention the alternative forward/backward 

### fills with next valid observation

when we find an empty cell, we can fill it with any type of value 

`df['date'].fillna(method='ffill', inplace=True)`

* Fill values:
    * by Mean / Median for numeric
    * by Mode for categorical
    * byForward / Backward fill for time series
* Interpolation for continuous data
* Drop rows `(df.dropna())` → Large datasets, few missing values
---
## 8. __Creating New Columns__

applying any operations between the columns
- `df['New_columns'] = df['column_x'] / df['column_y']`

### Heart rate reserve:

another way of applying any operations between the columns

- the new column name will be `Name = hrr`
- `df.eval('hrr = max_pulse - pulse', inplace=True)`
---
### 9.  __Flags__
---
* Weekend flag is a great example. Add a general principle:
    * Flags or derived columns should be meaningful for analysis, like identifying weekends, holidays, outliers, or categories.
---
### 10. __Code Practices__
* Encourage inplace=True for operations when you want to overwrite existing data.
* Always check results after each transformation: df.info()
* df.head()
* df.isnull().sum()

## Key Takeaways
- Data cleaning is essential and unavoidable
- Missing or corrupted data can appear in many forms
- No universal solution; method depends on dataset size, business goal, and importance of data
- Always inspect, document, and verify after each step
- Finding incorrect data is harder than fixing it
