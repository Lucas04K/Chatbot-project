# Day 14, 12.01.2026
Protocol writer: Louis

---
## __Introduction__
We started the day with how to create new environments in VSCode. Right after Merna gave us the introduction into Pandas Library which was followed by a corresponding group exercise. After the break we started the topic on how to select rows and columns in Pandas. After this lecture we proceeded to another group exercise on that topic. The day was closed by the exercise review and discussion.


## __Schedule__ 
|Time|Notes|

| 09:00 - 10:00 | Creating new environments <br>
| 10:00 - 11:00 | Introduction into Pandas Library <br>
| 11:00 - 11:30 | Pandas intro exercise <br>
| 11:30 - 12:00 | Exercise discussion <br>
| 13:00 - 14:00 | Pandas selecting rows and columns <br>
| 14:00 - 15:00 | Selecting rows and columns exercise <br>
| 15:00 - 15:30 | Exercise discussion <br>

---

## __Points in the lesson__ 

### __Environments__
`conda env list` check out which environments already exist. <br>
`conda create -n (new env-name)` creates new environment.<br>
- `python=(version)` ___(example: python=3.12)___ add a specific pyhton version.<br>
- `conda activate (environment name)` activates the new environment.<br>
<br>

### __Pandas Install__
`pip install pandas` installing pandas library via terminal<br>
`import pandas as pd` import pandas into your local kernel/environment<br>
<br>

### __DataFrame__
`pd.DataFrame()` create a manual dataframe. __!Make sure to use the capital letters!__<br>
`df.index(start,stop,step)` Check the row index<br>
`df.dtypes` see data types of df columns<br>
`df.name.dtype` see data type of a specifically targeted column<br>
`df.info()` overview on the dataframe<br>
`df.head()` show overview (first five rows) of dataframe.<br>
`df.tail()` show overview (last five rows) of DataFrame<br>
`df.shape()` gives you the numbers of rows and columns<br>
`df.columns` gives you the columns names and data types<br>
`df.describe()` gives you statistical overview on the df<br>
`df.columns_name.describe()` gives you statistical overview on a targeted column<br>
`df.describe(include=”all”)` gives you statistical overview on all columns of the df<br>
<br>

### __Pandas file reading__
`pd = pd.read_csv(”my_data.csv”)` loading a csv-file into a named pandas dataframe<br>
`pd = pd.read_csv(”my_data.csv”, header=None, names=[”col1”, “col2”, “col3”])` specifying that headers are not taken from the loaded dataset.
- With `“names=”` headers will be named manually.<br>

`pd = pd.read_csv(”my_data.csv”, sep=”targeted seperation character”)` specify specific seperation character inside the dataset. Standard seperator is “,”.<br>
`penguins.to_csv(”./data_path”)` export and save DataFrame to a new csv-file<br>
- `penguins.to_excel("./data_path")`<br>
- `penguins.to_json("./data_path")`<br>
<br>


### __Selecting rows and columns__
`df.columns` shows you the columns of df.<br>
- Option to rename headers with `df.columns = […, …]`<br>

`df[”column_name”]` choose specific column (option to add additional columns)<br>
- With single `[]` it will return a series - with `[[]]` a DataFrame.<br>
`.astype(datatype)` specify/redefine data as a specific datatype (int, float, …)<br>
`df[”column_name”] = 2024` create and name new column + add column content.<br>
`df.drop(”column_name”, axis = “columns/rows”)` drop a column from the dataframe. With “inplace = True” you can overwrite the current df. Otherwise assign the change to new variable.<br>
`df.loc[”column_name”]` select specific row(s) or column(s) by label. Includes the last mentioned label.<br>
`df.set_index(”column_name”, inplace = True)` set a column as new index. With "inplace=True" the old index will be overwritten.<br>
`df.iloc[5]` select specific row(s) or column(s) by index (integer location).<br>
<br>

---