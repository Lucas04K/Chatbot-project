# Day 19, 19.01.2026
Protocol writer: Andrea

---
## __Introduction__
As usual, we started the day with the minutes. Then Merna joined us and we first discussed the exercises before moving on to the new topic. Merna announced that from now on, one person from each group would present part of the previous day's exercises.

---

## Schedule

**09:00 – 09:20**  
Protocol discussion  

**09:30 – 10:30**  
Presentation of Friday's exercise (16 January 2026)  

**11:00 – 12:00**  
First part of the daily lesson: "Aggregation and GroupBy"  

**12:00 – 13:00**  
Break  

**13:00 – 14:10**  
Second part of the daily lesson: "Aggregation and GroupBy"  


---
---
# Topic: Data Aggregation & GroupBy in Pandas (Penguins dataset)

### Goal of the session
Understand how to **group data** and **summarize it per group** using Pandas, so we can compare subsets (e.g., species, island, sex).

---

## 1) Workflow we followed (the “how”)

### Step 1 — Load and check the dataset
- Loaded the built-in dataset: `penguins = sns.load_dataset('penguins')`
- Quick inspection:
  - `penguins` (table view)
  - `penguins.head()` (first rows)
- Why we did this:
  - confirm the dataset loaded correctly
  - understand columns and data types
  - detect missing values (`NaN`)

**Takeaway:** Always start with a quick data check before calculating anything.

---

### Step 2 — Basic metrics (single column)
- Calculated a simple mean: `penguins['bill_length_mm'].mean()`
- Checked categorical distribution (sex):
  - mode: `penguins['sex'].mode()`
  - counts: `penguins['sex'].value_counts()`
  - proportions: `penguins['sex'].value_counts(normalize=True)`

**Takeaway:** Use mean for numeric summaries, and mode/counts for categories.

---

### Step 3 — Aggregation syntax options (`agg()`)
We practiced three ways to write aggregation:

1. **List syntax** (same functions applied to selected column(s)):
   - `agg(['mean','median','std'])`
2. **Dictionary syntax** (different functions for different columns):
   - `{'colA':[...], 'colB':[...]}`
3. **Named aggregation (tuple syntax)** (give meaningful names to outputs):
   - `new_name=('column','function')`

**Takeaway:**  
- Use **list** when applying the same stats to one/multiple numeric columns.  
- Use **dict** when each column needs different stats.  
- Use **named aggregation** to create clean, readable output.

---

### Step 4 — GroupBy fundamentals (descriptive stats per group)
We learned the GroupBy logic:

- Create group object: `df_group = penguins.groupby('species')`
- Explore groups:
  - `df_group.groups` (which rows belong to which group)
  - `df_group.get_group('Adelie')` (inspect one group)
- Compute stats per group:
  - `penguins.groupby('species')['body_mass_g'].mean()`
- Compute multiple stats per group:
  - `penguins.groupby('species').agg({'body_mass_g':['mean','min','max']})`
- Use `describe()` for standard statistics:
  - `penguins.groupby('species').agg({'body_mass_g':['describe']})`

**Takeaway:**  
GroupBy is always: **split → apply → combine**.

---

### Step 5 — GroupBy + counting (frequencies & uniqueness)
We answered questions using counting tools:

- `count` vs `size`
  - `count` = non-null values only
  - `size` = all rows including `NaN`
- Unique values:
  - `nunique` = number of unique categories
- Most frequent value:
  - `pd.Series.mode`

We also grouped by multiple columns:
- `penguins.groupby(['species','sex'], dropna=False).size()`

**Takeaway (very important):**
- **`count` ≠ `size`**
- Use `dropna=False` to keep missing values visible as their own group.

---

### Step 6 — Min/Max comparisons by group
- Min/max per island:
  - `penguins.groupby('island').agg({'body_mass_g':['min','max']})`
- Extension: island + sex:
  - `penguins.groupby(['island','sex']).agg({'body_mass_g':['min','max']})`
- Include missing sex:
  - `dropna=False`

**Takeaway:**  
Grouping can be layered: **one key** (island) or **multiple keys** (island + sex).

---
---
## 2) What we learned (key concepts to remember)

### Core concepts
- **Aggregation** = summarizing values (mean, min, max, count, etc.)
- **GroupBy** = applying aggregation **per subgroup**
- Standard pattern: **groupby → select column(s) → aggregate**

### Missing values (NaN)
- Many numeric functions ignore NaN automatically (e.g., `mean`)
- For counting:
  - `count` ignores NaN
  - `size` includes NaN
- `dropna=False` makes missing categories visible in group results

### Choosing the right tool
- `mean/median/std` → numeric distribution
- `mode/value_counts` → category distribution
- `nunique` → number of unique categories
- `describe` → full default descriptive statistics

---
---

## 3) Extra notes (optional, if time allows)
### Variance (`var`)
- `var()` works only on numeric columns:
  - use `numeric_only=True` or select numeric columns first
- Variance is in **units squared** (e.g., g², mm²)

### `transform()`
- `transform()` returns the **same length as the original DataFrame**
- Useful for adding group-level values back to each row:
  - e.g., group sum or group mean per row

---
---
# What we learned as students
- How to check data structure quickly (`DataFrame`, `head()`, missing values).
- How to write flexible aggregations with `agg()` (list, dictionary, named aggregation).
- How `groupby()` works (GroupBy object, inspecting groups, computing metrics per group).
- The difference between `count` (excludes NaN) and `size` (includes NaN) + using `dropna=False`.
- How to group by multiple attributes (MultiIndex results).
- How `transform()` differs from aggregation (output length matches the original dataset).


